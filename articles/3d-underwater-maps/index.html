<!DOCTYPE html><html><head><meta charset=utf-8><meta content=@vulkd name=author><meta content="3d underwater maps" name=description><meta content="3d underwater maps" name=keywords><meta content="width=device-width,initial-scale=1" name=viewport><meta content=summary name=twitter:card><meta content=@vulkd name=twitter:site><meta content="3D Underwater Maps" name=twitter:title><meta content="3d underwater maps" name=twitter:description><meta content=https://vulkd.com/articles/3d-underwater-maps/twitter.png name=twitter:image><meta content=website property=og:type><meta content="3D Underwater Maps" property=og:title><meta content=vulkd.com property=og:site_name><meta content=https://vulkd.com/articles/3d-underwater-maps property=og:url><meta content="3d underwater maps" property=og:description><meta content=https://vulkd.com/articles/3d-underwater-maps/twitter.png property=og:image><meta content="3d underwater maps" property=og:image:alt><title>3D Underwater Maps</title><link href=https://fonts.googleapis.com rel=preconnect><link href=https://fonts.gstatic.com rel=preconnect crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Roboto+Mono&amp;display=swap" rel=stylesheet><style>body{margin:0;font-family:sans-serif;font-style:normal;background:#f7f4f2;color:#433c2d}img{width:100%;max-width:80ch;border:1px solid #433c2d}ol,p{max-width:80ch;line-height:1.6}h1,h2,h3,h4,h5,h6,p{padding:0 2rem}hr{border-color:#433c2d;margin:2rem 0 4rem}a,p{white-space:pre-wrap;word-wrap:break-word}pre{position:relative;padding:2rem;font-size:.8rem;overflow-x:auto;font-family:"Roboto Mono",monospace;font-weight:400;font-optical-sizing:auto;color:#433c2d;background:#dcd3bb}a{transition:all .16s ease-in-out;color:#433c2d}a:hover{color:#dcd3bb}</style></head><body><main><article><div class="include relative"><script src=https://cdnjs.cloudflare.com/ajax/libs/three.js/110/three.min.js crossorigin=anonymous integrity="sha256-gSh8eotzb/CVvCREGPUNgIWuDnTYnZvVOQnRrP1eDjI="></script><canvas id=three-geo style=height:50vh;width:100%></canvas><script src=include_threejs__OrbitControls.js></script><script src=include_threejs__threegeo.min.js></script><script src=include_threejs__include_threejs.js></script></div><h1>3D Underwater Maps</h1><p><em>April 2020</em></p><p><em>Note: Click, drag, and scroll to move around the 3d scene above. Height has been multiplied by a factor of 5 to make it more interesting.</em></p><p><em>Note: Ideally, I'd assume you would put together your own RGB-DEM tiles using some compiled global relief data instead of doing it in this roundabout way. But whatever, read on and have a laugh if you actually know what you're doing! Code can be found <a href=https://github.com/vulkd/hydroxy rel=noopener target=_blank>here</a>.</em></p><ol id=tos><li><a href=#map-tiling>Map Tiling</a></li><li><a href=#rgb-dem-tiles>RGB-DEM Tiles</a></li><li><a href=#three-geo>three-geo</a></li><li><a href=#modifying-rgb-dem-tiles>Modifying RGB-DEM Tiles</a></li><li><a href=#finding-bathymetry-data>Finding Bathymetry Data</a></li><li><a href=#hydroxy-and-redis>Hydroxy and Redis</a></li><li><a href=#drawing-bathymetry-data>Drawing Bathymetry Data</a></li><li><a href=#fixing-blank-spots>Fixing Blank Spots</a></li><li><a href=#miscellaneous>Miscellaneous</a></li></ol><hr><p>I spotted a <a href="https://www.youtube.com/watch?v=2ydmSr_ajQ4" rel=noopener target=_blank>music visualization</a> on Youtube that looked like it could be an underwater section in a video game or aquatic synthwave universe. Around the same time a fun three.js/mapbox mash-up <a href=https://github.com/w3reality/three-geo rel=noopener target=_blank>three-geo</a> came to my attention. Combining the resulting inspiration from both discoveries, I dived in and had a harpoon at doing some underwater modelling.</p><p>While we know a fair bit about Earth's terrestrial elevation, <a href=https://en.wikipedia.org/wiki/Hypsometry rel=noopener target=_blank>hypsometry</a>, comparatively little is known about its <a href=https://en.wikipedia.org/wiki/Bathymetry rel=noopener target=_blank>bathymetry</a>. <a href=https://en.wikipedia.org/wiki/Global_relief_model rel=noopener target=_blank>Global relief models</a> attempt to combine both types of elevation regardless of water or ice coverage. Bathymetric surveying has come a long way from lowering cables into the ocean - now tech such as <a href=https://en.wikipedia.org/wiki/Multibeam_echosounder rel=noopener target=_blank>multibeam</a> SONAR, <a href=https://academic.oup.com/gji/article/83/1/263/570088 rel=noopener target=_blank>measuring gravitational anomalies</a>, and LIDAR (though not so much) are tools of the trade.</p><p>Webmaps with the 3d-perspective capabilities that let the user intuitively view mountains etc. don't include the ocean floor in their 3d models, even though there's a wealth of <a href=https://maps.ngdc.noaa.gov/viewers/bathymetry/ rel=noopener target=_blank>data out there</a> <em>(Understandably, high-resolution bathy data isn't available for most of the sea floor. Without new tech, it would require a monumental - some might say impossible - effort on humanities part to map the ocean's elevation to the same level of detail as we have on land)</em>.</p><p><em>Note: There seems to have been <a href=https://github.com/AnalyticalGraphicsInc/cesium/pull/6047 rel=noopener target=_blank>a push</a> to add subterranean and submarine capabilities to Cesium a while ago.</em></p><p><a href=offish-audio-visualization.png><img alt="Offish audio visualization" src=offish-audio-visualization.png></a></p><hr><h2 id=map-tiling>Map Tiling</h2><p>Map tiles come in two forms - raster (images) and vector (data with coordinates attached). Both can also be used (ie: 'hybrid' satellite maps). For an easy explanation see <a href=https://www.maptiler.com/news/2019/02/what-are-vector-tiles-and-why-you-should-care/ rel=noopener target=_blank>this Maptiler publication</a>.</p><p>Using a <a href=https://wiki.openstreetmap.org/wiki/QuadTiles rel=noopener target=_blank>quadtree</a> means a user can move around the map and only render the area they're viewing, and not some impossible umpteenth-pixel image file. It also means that with the 5.65gb of space left on my laptop, I'm not about to generate my own RGB-DEM global relief tileset, so I'll stick with modifying Mapbox's for now. The bounding box of the earth at each zoom level is split into <code>2^z * 2^z</code> tiles, each tile represented by its x/y/z coordinates:</p><p><a href=tile-example.png><img alt="Tile example" src=tile-example.png></a></p><p><em>Image from <a href=https://www.maptiler.com/news/2019/02/what-are-vector-tiles-and-why-you-should-care/ rel=noopener target=_blank>Maptiler - What are vector tiles and why you should care</a>.</em></p><hr><h2 id=rgb-dem-tiles>RGB-DEM Tiles</h2><p>Encoding height data into a tile can be done via mapping a pixel's brightness to metres in grayscale. I'm unaware of any raster DEM data making use of alpha values, or the values of surrounding pixels to contribute to one pixel's height value - in all practical cases unnecessary, as RGB-DEM tiles offer a whopping <em><strong>16777216 possible values per pixel</strong></em> (that's base-256!):</p><p><a href=mapbox-rgb-dem-tile.png><img alt="Mapbox rgb dem tile" src=mapbox-rgb-dem-tile.png></a></p><p>A page from 2011 detailing how engineers at <a href=https://www.klokantech.com/ rel=noopener target=_blank>Klokantech</a> (Definitely have a look at their projects page!) came up with <a href=https://www.klokantech.com/labs/dem-color-encoding rel=noopener target=_blank>an interesting method</a> relying on a Z-order curve to specify shades of blue/purple for water, and land green/red. Mapbox however use a fairly standard approach with metre increments that relies mainly on green and blue channels. Each pixel's RGB channels can be converted to height in metres like this:</p><pre class=notranslate style=""><code class=language-js>function rgbToHeight(r, g, b) {
    return -10000 + (r * 256 * 256 + g * 256 + b) * 0.1;
}
</code></pre><p>With data from a 512x512px terrain tile, we have a z-axis value for each x/y coordinate on a 512x512px raster tile!</p><hr><h2 id=three-geo>three-geo</h2><p>Due to mostly standardized tiling systems, matching satellite tiles to terrain tiles is easy - each tile should cover exactly the same area.</p><p><a href=https://github.com/w3reality/three-geo rel=noopener target=_blank>three-geo</a> uses data from <a href=https://docs.mapbox.com/help/troubleshooting/access-elevation-data rel=noopener target=_blank>Mapbox's terrain tiles</a> to generate a subdivided plane (using triangles, otherwise the result would look a lot like Minecraft) representing the elevation of that area. As far as I'm aware this is a form of <a href=https://en.wikipedia.org/wiki/Triangulated_irregular_network rel=noopener target=_blank>TIN</a>.</p><p>Satellite tile(s) corresponding to the same area are applied to the mesh as a texture, giving us a <a href=https://observablehq.com/@j-devel/hello-3d-geographic-terrains rel=noopener target=_blank>great 3d view</a>. (I'm trying to be mobile-friendly - if you're not reading this on a phone also have a look <a href=https://w3reality.github.io/three-geo/examples/geo-viewer/io/index.html rel=noopener target=_blank>this example</a>).</p><hr><h2 id=modifying-rgb-dem-tiles>Modifying RGB-DEM Tiles</h2><p>Modifying the existing mesh in threejs with bathy data is a possibility, but using terrain tiles is the goal. Before gathering any bathymetry data, I done a quick test.</p><ul><li>Loaded up an area in three-geo and retrieved the terrain tile URL and response via devtools.</li><li>Had three-geo to reroute requests for that URL to a local proxy server that responded with the modified tile.</li><li>Used <a href=https://jspaint.app/ rel=noopener target=_blank>jspaint.app</a> to make some bitmap edits:</li></ul><p><a href=modified-rgb-dem-hello-world-tile-alongside-map.png><img alt="Modified rgb dem hello world tile alongside map" src=modified-rgb-dem-hello-world-tile-alongside-map.png></a></p><p>All a bit useless without being able to draw specific values, though! To do that we've got to convert height to the appropriate RGB values using an inverse function, which also works for negative heights for a few km before the red channel loops over (read: future adjustments needed for <a href=https://en.wikipedia.org/wiki/Challenger_Deep rel=noopener target=_blank>Challenger Deep</a> <a href=https://link.springer.com/article/10.1007/s11001-011-9134-0 rel=noopener target=_blank>data</a>).</p><pre class=notranslate style=""><code class=language-js>function heightToRgb(h) {
    const min = 65536;
    const max = 100000;
    const M = max + h * 10;

    const r = Math.floor(M / min);
    const g = Math.floor(M / 256) - r * 256;
    const b = Math.floor(M) - r * min - g * 256;

    return { r, g, b };
}
</code></pre><p><a href=modified-rgb-dem-ziggurat-tile-alongside-map.png><img alt="Modified rgb dem ziggurat tile alongside map" src=modified-rgb-dem-ziggurat-tile-alongside-map.png></a></p><p>For the sake of time we're going to haphazardly assume anything below sea level (0) is water, which won't work everywhere (<a href=https://en.wikipedia.org/wiki/List_of_places_on_land_with_elevations_below_sea_level rel=noopener target=_blank>list of places on land with elevations below sea level</a>).</p><h3>Converting lat/lons to x/y Tile Coordinates</h3><p>Now with a set of real-world lat/lon coordinates, we need to find the appropriate tile and pixels in that tile to modify. How do we do it? I knew it was possible given the initial conversion of bounding box to map tiles, and having to calculate what tiles need to render when rotating / pitching a 3d web map, but I ended up going around in circles like a complete <a href=https://en.wikipedia.org/wiki/Drongo#Insult rel=noopener target=_blank>drongo</a>... Stuff I looked at first:</p><ul><li><a href=https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames rel=noopener target=_blank>OSM's methods</a> on their wiki (which is superb).</li><li>Leaflet's <a href=https://github.com/Leaflet/Leaflet/blob/master/src/geo/projection/Projection.SphericalMercator.js rel=noopener target=_blank>project/unproject</a> and <a href=https://github.com/Leaflet/Leaflet/blob/master/src/geometry/Transformation.js rel=noopener target=_blank>transform</a> methods...</li><li>... and mapbox-gl's equivalent...</li><li>... and <a href=https://github.com/mapbox/mapbox-gl-native rel=noopener target=_blank>mapbox-gl-native</a>'s equivalant.</li><li>Using haversine formula to map lat/lon distance to top of tile and left of tile, then transforming x/y pixel coords from that using resolution per pixel of the tile (<em>bad bad bad bad bad bad</em>).</li></ul><p>... As it turns out, there's a helpful Mapbox library <a href=https://github.com/mapbox/tilebelt rel=noopener target=_blank>@mapbox/tilebelt</a> with a bunch of great methods for map tiles that solves this question with ease! I ended up going with something similar:</p><pre class=notranslate style=""><code class=language-js>const DEG2RAD = Math.PI / 180.0;
const EARTH_RADIUS_M = 6378137;
const LATITUDE_MAX = 85.051128779806604;
const PIXEL_ORIGIN = { x: 1906658, y: 1325278 }; // From Leaflet for EPSG:3857

function getScale(z) {
    return 256 * Math.pow(2, z);
}

function project(lon, lat) {
    lat = Math.max(Math.min(LATITUDE_MAX, lat), -LATITUDE_MAX);
    const sin = Math.sin(lat * DEG2RAD);
    return {
        x: EARTH_RADIUS_M * lon * DEG2RAD,
        y: (EARTH_RADIUS_M * Math.log((1 + sin) / (1 - sin))) / 2,
    };
}

// https://stackoverflow.com/questions/40986573/project-leaflet-latlng-to-tile-pixel-coordinates
function lonLatToTilePixel(lon, lat, z, tileSize = 256) {
    const point = project(lon, lat);

    // Perform affine transformation for EPSG:3857
    const scale = getScale(z);
    const coefficient = 0.5 / (Math.PI * EARTH_RADIUS_M);
    point.x = scale * (coefficient * point.x + 0.5);
    point.y = scale * (-coefficient * point.y + 0.5);

    const tile = {
        x: Math.floor(point.x / tileSize),
        y: Math.floor(point.y / tileSize),
    };

    const tileCorner = {
        x: tile.x * tileSize - PIXEL_ORIGIN.x,
        y: tile.y * tileSize - PIXEL_ORIGIN.y,
    };

    return {
        tile,
        x: Math.round(point.x - PIXEL_ORIGIN.x - tileCorner.x),
        y: Math.round(point.y - PIXEL_ORIGIN.y - tileCorner.y),
    };
}

// Get target tile coord, and transform lon/lat to x/y pixels in that tile
// z - 1 due to tilesize diff (https://wiki.openstreetmap.org/wiki/Zoom_levels)
const { tile, x, y } = lonLatToTilePixel(lon, lat, z - 1, 512);
</code></pre><hr><h2 id=finding-bathymetry-data>Finding Bathymetry Data</h2><p>One pixel at a time is nice and all, but not so practical. Let's get some data to use, to modify multiple pixels.</p><p>There is some detailed bathy data served up by ArcGIS available on <a href=https://maps.thelist.tas.gov.au/listmap/app/list/map rel=noopener target=_blank>LISTmap</a>, processed via the following:</p><ul><li>Navigate ArcGIS' API throwing uninformative 400 errors for empty/invalid fields</li><li>Write script to download all features</li><li>Write script to merge and re-label features</li><li>Draw quick area of focus bbox with <a href=https://geojson.io rel=noopener target=_blank>geojson.io</a></li><li>Write nasty point-in-polygon script to remove all features outside of that bbox (ArcGIS server was throwing useless errors trying to do this via the API)</li><li>We're left with a pretty straightforward <a href=https://github.com/vulkd/hydroxy/blob/master/util/example-depth-data.geojson rel=noopener target=_blank>geojson file</a>.</li></ul><p><em>Note: The <a href=https://en.wikipedia.org/wiki/SS_Lake_Illawarra rel=noopener target=_blank>SS Lake Illawarra</a>'s shipwreck resides in the area of the tile I've been using (it collided with a bridge pylon). As such thereâ€™s been a few dives on it for various purposes. The Aussie science organization CSIRO have done <a href="https://www.youtube.com/watch?v=p97d6U6kNxY" rel=noopener target=_blank>surveys</a>. It would be cool to find some multibeam data (CSIRO's never got published to the web afaik, though could email them) and mix it with threejs.</em></p><hr><h2 id=hydroxy-and-redis>Hydroxy and Redis</h2><p>Now I want to be able to load new areas of the map, without having to generate every tile beforehand. To do this we can go through <code>example-depth-data.geojson</code> and convert those coords to x/y positions on their corresponding map tile coordinates. Simply loop through the coordinates, get each one's depth somehow, convert them to tile coordinates and store them in Redis with the key being their slippy map tile coordinate.</p><ul><li>Key: <code>z:y:x</code></li><li>Value: <code>[{x, y, z}, {x, y, z}, ...etc]</code></li></ul><p>When a tile is requested from the <a href=https://github.com/vulkd/hydroxy/blob/master/hydroxy.js rel=noopener target=_blank>proxy server</a>, download the tile from Mapbox and check if the tile's z/y/x coordinate is in Redis. If it is, use the stored value(s) to modify the tile and cache it for later use. Cache busting could be set in the client (eg; route query) or server (eg; check Redis value for changes, keep track of tile's last edited timestamp(s)) to reflect additional changes to each tile.</p><p><a href=hydroxy-flowchart.png><img alt="Hydroxy flowchart" src=hydroxy-flowchart.png></a></p><hr><h2 id=drawing-bathymetry-data>Drawing Bathymetry Data</h2><p>Now, with some co-ordinates, we can plot the resulting GeoJSON with the <a href=https://github.com/vulkd/hydroxy/blob/master/generatePixelCoords.js rel=noopener target=_blank>previous script</a>!</p><p><a href=bathymetry-tracks-added-to-mesh.png><img alt="Bathymetry tracks added to mesh" src=bathymetry-tracks-added-to-mesh.png></a></p><p><em>Note: There are two things to be aware of when using bathy data likes this. First are the aforementioned locations below sea-level. A check could be put in place for those locations, though there's bound to be anomalies. Second, some bathymetric data measures riverbeds, lakes, etc. and a check needs to be made so as to not plot a 10-meter deep mountain river as 10 meters below the ocean (eg if elevation is greater than sea level don't render it).</em></p><hr><h2 id=fixing-blank-spots>Fixing Blank Spots</h2><p>Due to the nature of bathymetric surveys we're often left with plenty of areas with an unknown depth. There are suitable methods for interpolating bathymetry data:</p><ul><li><a href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0216792&amp;type=printable" rel=noopener target=_blank>https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0216792&amp;type=printable</a></li><li><a href=https://gis.stackexchange.com/questions/210223/which-interpolation-technique-is-suitable-for-a-bathymetry-of-a-small-lake rel=noopener target=_blank>https://gis.stackexchange.com/questions/210223/which-interpolation-technique-is-suitable-for-a-bathymetry-of-a-small-lake</a></li><li><a href=https://pubs.er.usgs.gov/publication/ofr8928 rel=noopener target=_blank>https://pubs.er.usgs.gov/publication/ofr8928</a></li><li><a href=https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018EA000539 rel=noopener target=_blank>https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2018EA000539</a></li><li><a href=https://www.researchgate.net/post/Is_IDW_suitable_when_interpolating_bathymetry_out_of_echo_sounder_data rel=noopener target=_blank>https://www.researchgate.net/post/Is_IDW_suitable_when_interpolating_bathymetry_out_of_echo_sounder_data</a></li></ul><p>At the moment I'm just taking polylines and converting them to polygons with the same depth value, and layered them to draw the deeper areas last. So not accurate, just a neat aesthetic at this stage! Here's some of the bathy data drawn onto a canvas and filled in with a polygon fill algorithm to illustrate the problem of not having closed linestrings (magenta is where top-down fill stops):</p><p><a href=interpolation-missing-lines.png><img alt="Interpolation missing lines" src=interpolation-missing-lines.png></a></p><p>Connecting each vertex of each polygon with a <a href=https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm rel=noopener target=_blank>line drawing algorithm</a> gives us a closed loop we can <a href=https://alienryderflex.com/polygon_fill/ rel=noopener target=_blank>fill in</a>, giving us a modified tile with nicer looking results:</p><p><a href=bathymetry-interpolated-and-height-multiplied.png><img alt="Bathymetry interpolated and height multiplied" src=bathymetry-interpolated-and-height-multiplied.png></a></p><p><a href=mapbox-rgb-dem-tile-modified-with-bathymetry-data.png><img alt="Mapbox rgb dem tile modified with bathymetry data" src=mapbox-rgb-dem-tile-modified-with-bathymetry-data.png></a></p><hr><h2 id=miscellaneous>Miscellaneous</h2><ul><li>Kinda want to build a <a href=http://www.homebuiltrovs.com rel=noopener target=_blank>DIY ROV</a> now.</li><li>It would be amazing to render a ROV or ship's position, render each multibeam scan, and update bathymetry all in real time.</li><li>I recommend trying an exponential function to exaggerate height a little more at greater elevations for artistic purposes.</li><li>Simply softening an image and increasing its exposure resulted in some pretty sweet - if inaccurate - contours:</li></ul><p><a href=contoured-wireframe-landscape.png><img alt="Contoured wireframe landscape" src=contoured-wireframe-landscape.png></a></p><h3>Modifying the Wireframe Shader</h3><p>To visually differentiate land / water later on, I wrote my first shader to change the colour of the wireframe material depending on height. A few people have convinced me to look at WebGL sans-threejs which should be interesting and would give a more thorough understanding of how threejs works:</p><pre class=notranslate style=""><code class=language-js>new THREE.ShaderMaterial({
    wireframe: true,
    fragmentShader: `
    	varying vec3 vColor;

    	void main() {
    		gl_FragColor.rgb = vColor;
    	}
    `,
    vertexShader: `
    	varying vec3 vColor;
    	float h;

    	void main() {
    		h = position.z;

    		if (h == 0.0) {
    			vColor = vec3(0.0, 0.9, 0.9);
    		} else if (h &lt; 0.0) {
    			vColor = vec3(0.0, clamp(h, 0.5, 0.8), clamp(h, 0.5, 0.8));
    		} else {
    			vColor = vec3(0.65, 0.6, 0.4);
    		}

    		vec4 modelViewPosition = modelViewMatrix * vec4(position, 1.0);
    		gl_Position = projectionMatrix * modelViewPosition;
    	}
    `,
});
</code></pre><h3>Underwater Positioning Systems</h3><ul><li><a href=https://en.wikipedia.org/wiki/Underwater_acoustic_positioning_system rel=noopener target=_blank>https://en.wikipedia.org/wiki/Underwater_acoustic_positioning_system</a></li><li><a href=https://ieeexplore.ieee.org/document/1405510 rel=noopener target=_blank>https://ieeexplore.ieee.org/document/1405510</a></li><li><a href=https://www.asiatimes.com/2019/10/article/little-aussie-sub-creates-3d-underwater-maps/ rel=noopener target=_blank>https://www.asiatimes.com/2019/10/article/little-aussie-sub-creates-3d-underwater-maps/</a></li><li><a href=https://waterlinked.com/product/underwater-gps-explorer-kit/ rel=noopener target=_blank>https://waterlinked.com/product/underwater-gps-explorer-kit/</a></li><li><a href=https://www.businessinsider.com.au/uam-tec-submarine-google-street-view-2019-10 rel=noopener target=_blank>https://www.businessinsider.com.au/uam-tec-submarine-google-street-view-2019-10</a></li><li><a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4732074/ rel=noopener target=_blank>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4732074/</a></li><li><a href=https://www.researchgate.net/publication/309063343_Smart_Underwater_Positioning_System_and_Simultaneous_Communication rel=noopener target=_blank>https://www.researchgate.net/publication/309063343_Smart_Underwater_Positioning_System_and_Simultaneous_Communication</a></li><li><a href="https://www.youtube.com/watch?v=bU57kKsfjDY" rel=noopener target=_blank>https://www.youtube.com/watch?v=bU57kKsfjDY</a></li></ul><h3>Misc Bathymetry Links</h3><ul><li><a href=https://schmidtocean.org/technology/seafloor-mapping/ rel=noopener target=_blank>https://schmidtocean.org/technology/seafloor-mapping/</a></li><li><a href=https://ieeexplore.ieee.org/document/1002376 rel=noopener target=_blank>https://ieeexplore.ieee.org/document/1002376</a></li></ul></article></main></body></html>